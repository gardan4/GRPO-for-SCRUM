pip install \
    accelerate \
    transformers \
    trl \
    sentence-transformers \
    datasets \
    scikit-learn \
    pandas \
    tqdm \
    peft \
    trl[vllm] \

    torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128


CUDA_VISIBLE_DEVICES=0,1 python -m trl.scripts.vllm_serve --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --tensor-parallel-size 1 --data-parallel-size 2 --dtype bfloat16

CUDA_VISIBLE_DEVICES=0,1 python - <<'PY'
import sys, importlib, runpy
from transformers.models.auto.configuration_auto import CONFIG_MAPPING

# ── hot-patch: ignore duplicate “aimv2” registrations ───────────────
_orig_register = CONFIG_MAPPING.register
def _safe_register(key, cfg_cls, exist_ok=False):
    try:                                     # always allow duplicates
        _orig_register(key, cfg_cls, exist_ok=True)
    except ValueError:
        pass
CONFIG_MAPPING.register = _safe_register
# ────────────────────────────────────────────────────────────────────

# Re-create the argv that trl.scripts.vllm_serve expects
sys.argv = [
    "python -m trl.scripts.vllm_serve",
    "--model", "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "--tensor-parallel-size", "1",
    "--data-parallel-size",  "2",
    "--dtype", "bfloat16",
]

# Run the normal vLLM serve entry-point
runpy.run_module("trl.scripts.vllm_serve", run_name="__main__")
PY

